1. Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?
micro - вычисляет f вобщем, что хорошо для сбалансированных данных
macro - вычисляет f для каждого класса и возвращает их невзвешенное среднее без учета пропорции, что полезно при несбалансированных данных
weighted - вычисляет f для каждого класса и возвращает их среднее, взвешенное с учетом размера каждой выборки

2. В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?
Очень непростой вопрос. Пробовал разобраться в их устройстве,.. категориальные функции, наклон тангенса функции потерь, среднее кодирование, переоснащение... Сложновато пока. Надо еще подучиться.
 Если не углубляться, то CatBoost хорошо работает когда в данных есть категориальные переменные и мы должным образом их настроили
 XBoost эти переменные принимает в числовом виде и работает оччень небыстро, из-за чего настройка параметров может испортить настроение.
 Lightgbm при близкой к XBoost точности работает существенно быстрее (опять же если правильно настроить), что очень приятно
